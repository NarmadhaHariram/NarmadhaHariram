{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbdcfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a0ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862524de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "beceefa3",
   "metadata": {},
   "source": [
    "HTML Structure\n",
    "HTML (Hypertext Markup Language) serves as the foundation of web pages. Understanding its structure is crucial for web scraping.\n",
    "\n",
    "<html> is the root element of an HTML page.\n",
    "<head> contains meta-information about the HTML page.\n",
    "<body> displays the content on the web page, often the data of interest.\n",
    "<h3> tags are type 3 headings, making text larger and bold, typically used for player names.\n",
    "<p> tags represent paragraphs and contain player salary information.\n",
    "Composition of an HTML Tag\n",
    "HTML tags define the structure of web content and can contain attributes.\n",
    "\n",
    "An HTML tag consists of an opening (start) tag and a closing (end) tag.\n",
    "Tags have names (e.g., <a> for an anchor tag).\n",
    "Tags may contain attributes with an attribute name and value, providing additional information to the tag.\n",
    "HTML Document Tree\n",
    "HTML documents can be visualized as trees with tags as nodes.\n",
    "\n",
    "Tags can contain strings and other tags, making them the tag's children.\n",
    "Tags within the same parent tag are considered siblings.\n",
    "For example, the <html> tag contains both <head> and <body> tags, making them descendants of <html but children of <html>. <head> and <body> are siblings.\n",
    "Document Tree\n",
    "HTML Tables\n",
    "HTML tables are essential for presenting structured data.\n",
    "\n",
    "Define an HTML table using the <table> tag.\n",
    "Each table row is defined with a <tr> tag.\n",
    "The first row often uses the table header tag, typically <th>.\n",
    "The table cell is represented by <td> tags, defining individual cells in a row.\n",
    "HTML Table\n",
    "Web Scraping\n",
    "Web scraping involves extracting information from web pages using Python. It can save time and automate data collection.\n",
    "\n",
    "Required Tools:\n",
    "Web scraping requires Python code and two essential modules: Requests and Beautiful Soup. Ensure you have both modules installed in your Python environment.\n",
    "\n",
    "# Import Beautiful Soup to parse web page content\n",
    "from bs4 import BeautifulSoup\n",
    "Copied!\n",
    "Fetching and Parsing HTML:\n",
    "To start web scraping, you need to fetch the HTML content of a webpage and parse it using Beautiful Soup. Here's a step-by-step example:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Specify the URL of the webpage you want to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/IBM'\n",
    "# Send an HTTP GET request to the webpage\n",
    "response = requests.get(url)\n",
    "# Store the HTML content in a variable\n",
    "html_content = response.text\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# Display a snippet of the HTML content\n",
    "print(html_content[:500])\n",
    "Copied!\n",
    "Navigating the HTML Structure:\n",
    "BeautifulSoup represents HTML content as a tree-like structure, allowing for easy navigation. You can use methods like find_all to filter and extract specific HTML elements. For example, to find all anchor tags () and print their text:\n",
    "\n",
    "# Find all <a> tags (anchor tags) in the HTML\n",
    "links = soup.find_all('a')\n",
    "# Iterate through the list of links and print their text\n",
    "for link in links:\n",
    "    print(link.text)\n",
    "Copied!\n",
    "Custom Data Extraction:\n",
    "Web scraping allows you to navigate the HTML structure and extract specific information based on your requirements. This may involve finding specific tags, attributes, or text content within the HTML document.\n",
    "\n",
    "Using BeautifulSoup for HTML Parsing\n",
    "Beautiful Soup is a powerful tool for navigating and extracting specific parts of a web page. It allows you to find elements based on their tags, attributes, or text, making it easier to extract the information you're interested in.\n",
    "\n",
    "Using pandas read_html for Table Extraction\n",
    "On many websites, data is neatly organized in tables. Pandas, a Python library, provides a function called read_html, which can automatically extract data from these tables and present it in a format suitable for analysis. It's similar to taking a table from a webpage and importing it into a spreadsheet for further analysis.\n",
    "\n",
    "Conclusion\n",
    "In summary, this reading introduces web scraping with BeautifulSoup and Pandas, emphasizing extracting elements and tables. BeautifulSoup facilitates\n",
    "HTML parsing, while Pandas' read_html streamlines table extraction. Responsible web scraping is highlighted, ensuring adherence to website terms. Armed with this knowledge, you can confidently engage in precise data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8668d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cheat Sheet : API's and Data Collection\n",
    "Package/Method\tDescription\tCode Example\n",
    "Accessing element attribute\tAccess the value of a specific attribute of an HTML element.\tSyntax:\n",
    "1\n",
    "attribute = element[(attribute)]\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "href = link_element[(href)]\n",
    "Copied!\n",
    "BeautifulSoup()\tParse the HTML content of a web page using BeautifulSoup. The parser type can vary based on the project.\tSyntax:\n",
    "1\n",
    "soup = BeautifulSoup(html, (html.parser))\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "html = (https://api.example.com/data) soup = BeautifulSoup(html, (html.parser))\n",
    "Copied!\n",
    "delete()\tSend a DELETE request to remove data or a resource from the server. DELETE requests delete a specified resource on the server.\tSyntax:\n",
    "1\n",
    "response = requests.delete(url)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "response = requests.delete((https://api.example.com/delete))\n",
    "Copied!\n",
    "find()\tFind the first HTML element that matches the specified tag and attributes.\tSyntax:\n",
    "1\n",
    "element = soup.find(tag, attrs)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "first_link = soup.find((a), {(class): (link)})\n",
    "Copied!\n",
    "find_all()\tFind all HTML elements that match the specified tag and attributes.\tSyntax:\n",
    "1\n",
    "elements = soup.find_all(tag, attrs)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "all_links = soup.find_all((a), {(class): (link)})</td>\n",
    "Copied!\n",
    "findChildren()\tFind all child elements of an HTML element.\tSyntax:\n",
    "1\n",
    "children = element.findChildren()\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "child_elements = parent_div.findChildren()\n",
    "Copied!\n",
    "get()\tPerform a GET request to retrieve data from a specified URL. GET requests are typically used for reading data from an API. The response variable will contain the server's response, which you can process further.\tSyntax:\n",
    "1\n",
    "response = requests.get(url)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "response = requests.get((https://api.example.com/data))\n",
    "Copied!\n",
    "Headers\tInclude custom headers in the request. Headers can provide additional information to the server, such as authentication tokens or content types.\tSyntax:\n",
    "1\n",
    "headers = {(HeaderName): (Value)}\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "base_url = (https://api.example.com/data) headers = {(Authorization): (Bearer YOUR_TOKEN)} response = requests.get(base_url, headers=headers)\n",
    "Copied!\n",
    "Import Libraries\tImport the necessary Python libraries for web scraping.\tSyntax:\n",
    "1\n",
    "from bs4 import BeautifulSoup\n",
    "Copied!\n",
    "json()\tParse JSON data from the response. This extracts and works with the data returned by the API. The response.json() method converts the JSON response into a Python data structure (usually a dictionary or list).\tSyntax:\n",
    "1\n",
    "data = response.json()\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "2\n",
    "response = requests.get((https://api.example.com/data)) \n",
    "data = response.json()\n",
    "Copied!\n",
    "next_sibling()\tFind the next sibling element in the DOM.\tSyntax:\n",
    "1\n",
    "sibling = element.find_next_sibling()\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "next_sibling = current_element.find_next_sibling()\n",
    "Copied!\n",
    "parent\tAccess the parent element in the Document Object Model (DOM).\tSyntax:\n",
    "1\n",
    "parent = element.parent\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "parent_div = paragraph.parent\n",
    "Copied!\n",
    "post()\tSend a POST request to a specified URL with data. Create or update POST requests using resources on the server. The data parameter contains the data to send to the server, often in JSON format.\tSyntax:\n",
    "1\n",
    "response = requests.post(url, data)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "response = requests.post((https://api.example.com/submit), data={(key): (value)})\n",
    "Copied!\n",
    "put()\tSend a PUT request to update data on the server. PUT requests are used to update an existing resource on the server with the data provided in the data parameter, typically in JSON format.\tSyntax:\n",
    "1\n",
    "response = requests.put(url, data)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "response = requests.put((https://api.example.com/update), data={(key): (value)})\n",
    "Copied!\n",
    "Query parameters\tPass query parameters in the URL to filter or customize the request. Query parameters specify conditions or limits for the requested data.\tSyntax:\n",
    "1\n",
    "params = {(param_name): (value)}\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "2\n",
    "3\n",
    "base_url = \"https://api.example.com/data\"\n",
    "params = {\"page\": 1, \"per_page\": 10}\n",
    "response = requests.get(base_url, params=params)\n",
    "Copied!\n",
    "select()\tSelect HTML elements from the parsed HTML using a CSS selector.\tSyntax:\n",
    "1\n",
    "element = soup.select(selector)\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "titles = soup.select((h1))\n",
    "Copied!\n",
    "status_code\tCheck the HTTP status code of the response. The HTTP status code indicates the result of the request (success, error, redirection). Use the HTTP status codeIt can be used for error handling and decision-making in your code.\tSyntax:\n",
    "1\n",
    "response.status_code\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "2\n",
    "3\n",
    "url = \"https://api.example.com/data\"\n",
    "response = requests.get(url)\n",
    "status_code = response.status_code\n",
    "Copied!\n",
    "tags for find() and find_all()\tSpecify any valid HTML tag as the tag parameter to search for elements of that type. Here are some common HTML tags that you can use with the tag parameter.\tTag Example:\n",
    "\n",
    "- (a): Find anchor () tags.\n",
    "- (p): Find paragraph ((p)) tags.\n",
    "- (h1), (h2), (h3), (h4), (h5), (h6): Find heading tags from level 1 to 6 ( (h1),n (h2)).\n",
    "- (table): Find table () tags.\n",
    "- (tr): Find table row () tags.\n",
    "- (td): Find table cell ((td)) tags.\n",
    "- (th): Find table header cell ((td))tags.\n",
    "- (img): Find image ((img)) tags.\n",
    "- (form): Find form ((form)) tags.\n",
    "- (button): Find button ((button)) tags.\n",
    "Copied!\n",
    "text\tRetrieve the text content of an HTML element.\tSyntax:\n",
    "1\n",
    "text = element.text\n",
    "Copied!\n",
    "Example:\n",
    "\n",
    "1\n",
    "title_text = title_element.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
